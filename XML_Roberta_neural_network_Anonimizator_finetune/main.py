import os
import json
from transformers import Trainer, TrainingArguments, DataCollatorForTokenClassification, EarlyStoppingCallback

# –ò–º–ø–æ—Ä—Ç –Ω–∞—à–∏—Ö –º–æ–¥—É–ª–µ–π
import configs as cfg
import data_loader
import model_builder
import utils
import torch

def main():
    print("üöÄ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—É—á–µ–Ω–∏—è NER...")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üñ•Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

    if device.type == 'cuda':
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   –ü–∞–º—è—Ç—å: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.2f} GB")
    else:
        print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –û–±—É—á–µ–Ω–∏–µ –±—É–¥–µ—Ç –∏–¥—Ç–∏ –Ω–∞ CPU. –≠—Ç–æ –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ!")

    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    if not os.path.exists(cfg.TRAIN_FILE) or not os.path.exists(cfg.VAL_FILE):
        if not os.path.exists(cfg.SOURCE_FILE):
            raise FileNotFoundError(f"–ù–µ—Ç –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {cfg.SOURCE_FILE}")
        data_loader.split_and_save_data(cfg.SOURCE_FILE, cfg.TRAIN_FILE, cfg.VAL_FILE)

    # 2. –°–æ–∑–¥–∞–Ω–∏–µ Dataset –æ–±—ä–µ–∫—Ç–æ–≤
    # –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–µ–º train, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–µ—Ç–æ–∫
    train_ds, label2id = data_loader.create_dataset(cfg.TRAIN_FILE)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ label2id –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    val_ds, _ = data_loader.create_dataset(cfg.VAL_FILE, label2id=label2id)

    label_list = list(label2id.keys())
    print(f"üè∑Ô∏è –ö–ª–∞—Å—Å—ã ({len(label_list)}): {label_list}")

    # 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞
    if cfg.TRAINING_MODE == "new":
        model, tokenizer = model_builder.get_base_model(cfg.MODEL_CONFIG["base_model"], label2id)
    elif cfg.TRAINING_MODE == "continue":
        model, tokenizer = model_builder.load_existing_model(cfg.MODEL_CONFIG["existing_model"])
    elif cfg.TRAINING_MODE == "extend":
        model, tokenizer = model_builder.extend_model(cfg.MODEL_CONFIG["existing_model"], label2id)
    else:
        raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ä–µ–∂–∏–º: {cfg.TRAINING_MODE}")

    # 4. –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ (—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º partial —Ñ—É–Ω–∫—Ü–∏—é –∏–ª–∏ lambda –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞
    tokenize_fn = lambda x: utils.align_labels_with_tokens(x, tokenizer, cfg.MODEL_CONFIG["max_length"])

    print("‚öôÔ∏è –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è...")
    train_encoded = train_ds.map(tokenize_fn, batched=True)
    val_encoded = val_ds.map(tokenize_fn, batched=True)

    # 5. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è
    args = TrainingArguments(
        output_dir=cfg.OUTPUT_DIR,
        learning_rate=cfg.TRAIN_PARAMS["learning_rate"],
        per_device_train_batch_size=cfg.TRAIN_PARAMS["batch_size"],
        num_train_epochs=cfg.TRAIN_PARAMS["num_epochs"],
        weight_decay=cfg.TRAIN_PARAMS["weight_decay"],
        eval_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
        metric_for_best_model="f1",
        logging_dir=os.path.join(cfg.OUTPUT_DIR, "logs"),
        fp16=True,  # –û—Å—Ç–∞–≤—å—Ç–µ True, –µ—Å–ª–∏ –∫–∞—Ä—Ç–∞ —Å–µ—Ä–∏–∏ RTX (20xx, 30xx, 40xx)
        no_cuda=False,
        dataloader_num_workers=0  # –ù–∞ Windows –ª—É—á—à–µ –æ—Å—Ç–∞–≤–∏—Ç—å 0 –∏–ª–∏ 1, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∑–∞–≤–∏—Å–∞–Ω–∏–π
    )

    # 6. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Trainer
    trainer = Trainer(
        model=model,
        args=args,
        train_dataset=train_encoded,
        eval_dataset=val_encoded,
        tokenizer=tokenizer,
        data_collator=DataCollatorForTokenClassification(tokenizer),
        compute_metrics=utils.compute_metrics_factory(label_list),
        callbacks=[EarlyStoppingCallback(early_stopping_patience=cfg.TRAIN_PARAMS["patience"])]
    )

    # 7. –ó–∞–ø—É—Å–∫
    print("\nüî• –°—Ç–∞—Ä—Ç –æ–±—É—á–µ–Ω–∏—è...")
    trainer.train()

    # 8. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ {cfg.OUTPUT_DIR}")
    trainer.save_model(cfg.OUTPUT_DIR)
    tokenizer.save_pretrained(cfg.OUTPUT_DIR)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥ –º–µ—Ç–æ–∫ –æ—Ç–¥–µ–ª—å–Ω–æ (–ø–æ–ª–µ–∑–Ω–æ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞)
    with open(os.path.join(cfg.OUTPUT_DIR, "label_map.json"), "w") as f:
        json.dump({"label2id": label2id, "id2label": {v: k for k, v in label2id.items()}}, f)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
    metrics = trainer.evaluate()
    print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: F1={metrics['eval_f1']:.4f}")


if __name__ == "__main__":
    main()