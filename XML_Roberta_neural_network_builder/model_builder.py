import torch
from transformers import AutoModelForTokenClassification, AutoTokenizer


def get_base_model(model_name, label2id):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —á–∏—Å—Ç—É—é –º–æ–¥–µ–ª—å —Å –Ω—É–ª—è."""
    print(f"üÜï –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {model_name}")
    id2label = {v: k for k, v in label2id.items()}
    model = AutoModelForTokenClassification.from_pretrained(
        model_name,
        num_labels=len(label2id),
        id2label=id2label,
        label2id=label2id
    )
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    return model, tokenizer


def load_existing_model(model_path):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —É–∂–µ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å."""
    print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏: {model_path}")
    model = AutoModelForTokenClassification.from_pretrained(model_path)
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    return model, tokenizer


def extend_model(model_path, new_label2id):
    """
    –†–∞—Å—à–∏—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å –Ω–æ–≤—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏.
    –ö–æ–ø–∏—Ä—É–µ—Ç –≤–µ—Å–∞ –¥–ª—è —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö –∫–ª–∞—Å—Å–æ–≤.
    """
    print(f"üîß –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model_path}...")

    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ä—É—é –º–æ–¥–µ–ª—å
    old_model = AutoModelForTokenClassification.from_pretrained(model_path)
    old_tokenizer = AutoTokenizer.from_pretrained(model_path)
    old_label2id = old_model.config.label2id

    # 2. –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å —Å –Ω–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    new_id2label = {v: k for k, v in new_label2id.items()}
    new_model = AutoModelForTokenClassification.from_pretrained(
        model_path,
        num_labels=len(new_label2id),
        id2label=new_id2label,
        label2id=new_label2id,
        ignore_mismatched_sizes=True
    )

    # 3. –ö–æ–ø–∏—Ä—É–µ–º –≤–µ—Å–∞ (Smart Weights Transfer)
    print("   ‚öñÔ∏è –ü–µ—Ä–µ–Ω–æ—Å –≤–µ—Å–æ–≤...")
    with torch.no_grad():
        for label, old_id in old_label2id.items():
            if label in new_label2id:
                new_id = new_label2id[label]
                # –ö–æ–ø–∏—Ä—É–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (weights + bias)
                new_model.classifier.weight[new_id] = old_model.classifier.weight[old_id]
                new_model.classifier.bias[new_id] = old_model.classifier.bias[old_id]

    return new_model, old_tokenizer